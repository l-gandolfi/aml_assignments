{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, classification_report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, cmap=plt.cm.Blues):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Normalize\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(x_train, y_train, x_test, y_test):\n",
    "    # define the model's parameters\n",
    "    svc = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "    \n",
    "    # train the model on the train set\n",
    "    svc.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    # predict test set labels\n",
    "    y_pred = svc.predict(x_test)\n",
    "    \n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred, classes=['Airplane', 'Bird', 'Dog', 'Horse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classification(x_train, y_train, x_test, y_test):\n",
    "    # create KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    # train the model using the training sets\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    # predict test set labels\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred, classes=['Airplane', 'Bird', 'Dog', 'Horse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    labels = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog', 6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}\n",
    "\n",
    "    # The data, split between train and test sets:\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # preprocess\n",
    "    x_test_new = []\n",
    "    y_test_new = []\n",
    "    x_train_new = []\n",
    "    y_train_new = []\n",
    "    \n",
    "    # Array of counter, each class has one, it was used to test different number of samples\n",
    "    count = [0, 0, 0, 0]\n",
    "    for i, j in zip(x_train, y_train):\n",
    "        if (j==0):\n",
    "            if(count[0]<5000):\n",
    "                x_train_new.append(i)\n",
    "                y_train_new.append(j)\n",
    "                count[0]+=1\n",
    "\n",
    "        elif (j==5):\n",
    "            if(count[1]<5000):\n",
    "                x_train_new.append(i)\n",
    "                y_train_new.append(j)\n",
    "                count[1]+=1\n",
    "\n",
    "        elif (j==7):\n",
    "            if(count[2]<5000):\n",
    "                x_train_new.append(i)\n",
    "                y_train_new.append(j)\n",
    "                count[2]+=1\n",
    "\n",
    "        elif (j==2):\n",
    "            if(count[3]<5000):\n",
    "                x_train_new.append(i)\n",
    "                y_train_new.append(j)\n",
    "                count[3]+=1\n",
    "\n",
    "    x_train = np.array(x_train_new).astype('float32')\n",
    "    y_train = np.array(y_train_new)\n",
    "\n",
    "    # Repeat for the test set\n",
    "    count = [0, 0, 0, 0]\n",
    "    for i, j in zip(x_test, y_test):\n",
    "        if (j==0):\n",
    "            if(count[0]<500):\n",
    "                x_test_new.append(i)\n",
    "                y_test_new.append(j)\n",
    "                count[0]+=1\n",
    "\n",
    "        elif (j==5):\n",
    "            if(count[1]<500):\n",
    "                x_test_new.append(i)\n",
    "                y_test_new.append(j)\n",
    "                count[1]+=1\n",
    "\n",
    "        elif (j==7):\n",
    "            if(count[2]<500):\n",
    "                x_test_new.append(i)\n",
    "                y_test_new.append(j)\n",
    "                count[2]+=1\n",
    "\n",
    "        elif (j==2):\n",
    "            if(count[3]<500):\n",
    "                x_test_new.append(i)\n",
    "                y_test_new.append(j)\n",
    "                count[3]+=1\n",
    "\n",
    "    x_test = np.array(x_test_new).astype('float32')\n",
    "    y_test = np.array(y_test_new)\n",
    "\n",
    "    # Normalize numbers\n",
    "    x_test = x_test / 255.\n",
    "    x_train = x_train / 255.\n",
    "\n",
    "    print(\"train shape:\",x_train.shape)\n",
    "    print(\"train labels shape:\",y_train.shape)\n",
    "    print(\"test shape:\",x_test.shape)\n",
    "    print(\"test labels shape:\",y_test.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(x1, y1):\n",
    "    print('Building t-SNE...')\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', \tlinewidth='1', alpha=0.8, label='Airplane')\n",
    "    plt.scatter(X_t[np.where(y1 == 2), 0], X_t[np.where(y1 == 2), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='Bird')\n",
    "    plt.scatter(X_t[np.where(y1 == 5), 0], X_t[np.where(y1 == 5), 1], marker='o', color='b', linewidth='1', alpha=0.8, label='Dog')\n",
    "    plt.scatter(X_t[np.where(y1 == 7), 0], X_t[np.where(y1 == 7), 1], marker='o', color='black', linewidth='1', alpha=0.8, label='Horse')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "x_train, y_train, x_test, y_test = prepare_data()\n",
    "\n",
    "# show the first n images in train and test set\n",
    "n=6\n",
    "plt.figure(figsize=(18, 4))\n",
    "for i in range(n):\n",
    "    # display train\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(32, 32, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    #display test\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test[i].reshape(32, 32, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First CUT\n",
    "\n",
    "In this first attempt we just cut at the end of the convolutional blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "x_train, y_train, x_test, y_test = prepare_data()\n",
    "\n",
    "# build the VGG16 network\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_shape = (32,32,3))\n",
    "#print(vgg16.summary())\n",
    "\n",
    "# change the model type\n",
    "model = Sequential()\n",
    "for layer in vgg16.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# add the flatten output\n",
    "model.add(Flatten())\n",
    "\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features\n",
    "train_features = model.predict(x_train)\n",
    "print(train_features.shape)\n",
    "test_features = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run SVM\n",
    "classification(train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second CUT\n",
    "\n",
    "In this second attempt we are going to cut just before the last block of convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "x_train, y_train, x_test, y_test = prepare_data()\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape = (32,32,3))\n",
    "vgg16 = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "# change the model type\n",
    "model = Sequential()\n",
    "for layer in vgg16.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# add the flatten output\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features\n",
    "train_features = model.predict(x_train)\n",
    "print(train_features.shape)\n",
    "test_features = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run SVM\n",
    "classification(train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third CUT\n",
    "\n",
    "In the last attempt we are going to cut after the third block of convolutions, which means one block before the Second CUT's version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "x_train, y_train, x_test, y_test = prepare_data()\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape = (32,32,3))\n",
    "vgg16 = Model(inputs=base_model.input, outputs=base_model.get_layer('block3_pool').output)\n",
    "\n",
    "# change the model type\n",
    "model = Sequential()\n",
    "for layer in vgg16.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# add the flatten output\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features\n",
    "train_features = model.predict(x_train)\n",
    "print(train_features.shape)\n",
    "test_features = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run SVM\n",
    "classification(train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commento veloce su K-NN vs SVM\n",
    "k-nn produce risultati meno performanti rispetto a svm, in particolare è influenzato molto dalla scelta dei vicini: al crescere del numero i risultati diminuiscono e ha il suo ottimo con 1 solo vicino, tuttavia non è sufficiente e SVM è migliore sia con LinearSVM sia con SVC one-versus-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
